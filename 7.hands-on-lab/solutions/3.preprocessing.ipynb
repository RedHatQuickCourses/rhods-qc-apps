{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c912c1f9-2279-4c6c-b989-9b292e49a504",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "Run this notebook to preprocess the data.\n",
    "This notebook scales the data, deals with data imbalance and generates a training subset.\n",
    "\n",
    "> **NOTE**: This notebook performs all the necessary steps to preprocess the data before training.\n",
    "You do not need to develop additional preprocessing steps.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc5f346-58ae-48a1-ad68-bf7a04cfecd2",
   "metadata": {},
   "source": [
    "Install the `imbalanced-learn` package.\n",
    "The notebook uses this package to rebalance the dataset by using resampling techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a6c276a-7754-4334-9f5d-fc00b404ae40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn==0.11.0 in /opt/app-root/lib/python3.9/site-packages (0.11.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/app-root/lib/python3.9/site-packages (from imbalanced-learn==0.11.0) (1.24.4)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /opt/app-root/lib/python3.9/site-packages (from imbalanced-learn==0.11.0) (1.2.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/app-root/lib/python3.9/site-packages (from imbalanced-learn==0.11.0) (3.2.0)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /opt/app-root/lib/python3.9/site-packages (from imbalanced-learn==0.11.0) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/app-root/lib/python3.9/site-packages (from imbalanced-learn==0.11.0) (1.3.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install imbalanced-learn==0.11.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31da1256-2896-4f06-89fd-717d528698b3",
   "metadata": {},
   "source": [
    "Import dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c952c8f9-5eb2-4435-9e24-0b288b0035c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from numpy import save, count_nonzero\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import RobustScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3a7e18-4a26-4ade-a5c3-4ad563cdd4d7",
   "metadata": {},
   "source": [
    "The following code scales the `Amount` and `Time` columns, then builds a training subset that contains a balanced number of each class (`Fraud`(1), `No Fraud`(0)).\n",
    "\n",
    "The result of preprocessing the data is the `data/training_samples.npy` file, which contains all columns except for the class, and `data/training_samples.npy`, which contains only the class column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67f70658-4f72-45eb-b0fc-69c172c16b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data processing done!\n"
     ]
    }
   ],
   "source": [
    "df = read_csv('data/creditcard.csv')\n",
    "\n",
    "rob_scaler = RobustScaler()\n",
    "\n",
    "df['scaled_amount'] = rob_scaler.fit_transform(\n",
    "    df['Amount'].values.reshape(-1, 1)\n",
    ")\n",
    "df['scaled_time'] = rob_scaler.fit_transform(\n",
    "    df['Time'].values.reshape(-1, 1)\n",
    ")\n",
    "df.drop(['Time', 'Amount'], axis=1, inplace=True)\n",
    "scaled_amount = df['scaled_amount']\n",
    "scaled_time = df['scaled_time']\n",
    "\n",
    "df.drop(['scaled_amount', 'scaled_time'], axis=1, inplace=True)\n",
    "df.insert(0, 'scaled_amount', scaled_amount)\n",
    "df.insert(1, 'scaled_time', scaled_time)\n",
    "\n",
    "X = df.drop('Class', axis=1)\n",
    "y = df['Class']\n",
    "sss = StratifiedKFold(n_splits=5, random_state=None, shuffle=False)\n",
    "\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    original_Xtrain = X.iloc[train_index]\n",
    "    original_ytrain = y.iloc[train_index]\n",
    "\n",
    "original_Xtrain = original_Xtrain.values\n",
    "original_ytrain = original_ytrain.values\n",
    "\n",
    "sm = SMOTE(sampling_strategy='minority', random_state=42)\n",
    "Xsm_train, ysm_train = sm.fit_resample(original_Xtrain, original_ytrain)\n",
    "\n",
    "save(f'data/training_samples.npy', Xsm_train)\n",
    "save(f'data/training_labels.npy', ysm_train)\n",
    "\n",
    "print('Data processing done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57e83635-73d4-4ebb-a2f0-d8e7cd9a60a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraud cases 227452\n",
      "No fraud cases 227452\n"
     ]
    }
   ],
   "source": [
    "num_frauds = count_nonzero(ysm_train)\n",
    "\n",
    "print(\"Fraud cases\", num_frauds)\n",
    "print(\"No fraud cases\", ysm_train.size - num_frauds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
